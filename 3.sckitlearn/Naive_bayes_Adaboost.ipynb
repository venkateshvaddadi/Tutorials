{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategies for Training and and Evaluation, Metrics used in ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order to test our ML methods we divide our dataset into 3 seperate portions training set, validation set and testing set.Training set is what we feed to the model in order for it to learn to solve the problem at hand.\n",
    "\n",
    "Hyper-parameters are special variables that can be used to control the learning process. These are not learnt during the training stage but are often tweaked based on the performance of the algorithm on another dataset called the validation set.\n",
    "\n",
    "Testing set is finally used to evaluate the performance of the model on unseen data.Unlike validation which does contribute indirectly to the training of the algorithm,testing is unseen and hence is used to compare the algorithm's performance with other algorithms or training paradigms.\n",
    "\n",
    "Common convention suggests the division of training,validation and test set in the ratio 7:1:2.But this ratio is flexible and highly depends on the problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We also need metrics to evaluate our algorithms and some of the common ones are :\n",
    "<ul>\n",
    "<li>Accuracy</li>\n",
    "<li>Precision</li>\n",
    "<li>Recall</li>\n",
    "<li>F1-score</li>\n",
    "<li>AUC score </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before looking into the metrics let's see the concept of confusion matrix.It's matrix that allows us to visualize the performance of the model in a tabular format and many of the above scores can be derived from it.\n",
    "In supervised learning for a binary classification problem confusion matrix can be seen as \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align='center'>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>Predicted Positive</th>\n",
    "    <th>Predicted Negative</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Actual Positive</b></td>\n",
    "    <td>True Positive(TP)</td>\n",
    "    <td>False Negative(FN)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>Actual Negative</b></td>\n",
    "    <td>False Positive(FP)</td>\n",
    "    <td>True Negative(TN)</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores can now be represented as constituents of the elements of Confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula for the different scores are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$$\n",
       "$$Precision = \\frac{TP}{TP+FP}$$\n",
       "$$Recall = \\frac{TP}{TP+FN}$$\n",
       "$$F1 = \\frac{2*Precision*Recall}{Precision+Recall} = \\frac{2*TP}{2*TP+FP+FN}$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "$$Precision = \\frac{TP}{TP+FP}$$\n",
    "$$Recall = \\frac{TP}{TP+FN}$$\n",
    "$$F1 = \\frac{2*Precision*Recall}{Precision+Recall} = \\frac{2*TP}{2*TP+FP+FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC score is calculated as the Area Under the Sensitivity(TPR)-(1-Specificity)$(FPR) Curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$Sensitivity = Recall = \\frac{TP}{TP+FN}$$\n",
       "$$Specificity = \\frac{TN}{FP+TN}$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$Sensitivity = Recall = \\frac{TP}{TP+FN}$$\n",
    "$$Specificity = \\frac{TN}{FP+TN}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of open-source datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Training Machine Learning algorithms requires data.The entire process involving collection,curation and labelling if any of the datasets requires a lot of resources.Fortunately, we have open-sources where such datasets are made available under minimal licensing.\n",
    "<br>\n",
    "Some dataset aggregators are :\n",
    "<ul>\n",
    "<li><a href = \"https://archive.ics.uci.edu\">UCI Machine Learning Repository</a></li>\n",
    "<li><a href = \"https://www.kaggle.com/\">Kaggle</a></li>\n",
    "<li><a href = \"https://www.openml.org/\">OpenML</a></li>\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will be using MNIST dataset for the following ML algorithms.MNIST is a dataset of handwritten digits ranging from 0-9.Each digit is represented as a pixel image of 28x28 dimension.The dataset contains vectorized representation of the said image as 784 dimensional vector. To work with this dataset we will Scikit-learn to fetch it from openml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = datasets.fetch_openml(\"mnist_784\", version=1, return_X_y=True,as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize some of the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X.loc[i].values.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7877\n",
       "7    7293\n",
       "3    7141\n",
       "2    6990\n",
       "9    6958\n",
       "0    6903\n",
       "6    6876\n",
       "8    6825\n",
       "4    6824\n",
       "5    6313\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Another thing we can check is whether there is class imbalance among the digits which we can see there is some\n",
    "#but they are very close in frequency so we don't need to take imbalance into consideration.\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets divide our dataset into train and test with a split of 0.8 and 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question : We saw how our dataset is made of digits represented as a 784 dimensional vector.Can we somehow reduce the dimension and how will that affect the classification performance among different models?(Hint : PCA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "### Naive Bayes Classifier\n",
       "Naive Bayes Classifier is based on Bayes' theorem where we assume conditional independence among the different pair features given the value of the class label.Given the class label y and features $x_{1}$ through $x_{n}$\n",
       "$$P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) P(x_1, \\dots, x_n \\mid y)}{P(x_1, \\dots, x_n)}$$\n",
       "\n",
       "As we assume them to be conditionally independent hence we can say\n",
       "$$P(x_1, \\dots, x_n \\mid y) = \\prod_{i=1}^{n} P(x_i \\mid y)$$\n",
       "\n",
       "Also as $P(x_1, \\dots, x_n)$ also called evidence, works as a scaling factor to make the probabilites sum up to 1 hence we can remove it to get\n",
       "$$\\begin{align}\\begin{aligned}P(y \\mid x_1, \\dots, x_n) \\propto P(y) \\prod_{i=1}^{n} P(x_i \\mid y)\\\\\\Downarrow\\\\\\hat{y} = \\arg\\max_y P(y) \\prod_{i=1}^{n} P(x_i \\mid y),\\end{aligned}\\end{align}$$\n",
       "\n",
       "Reference: <a href=\"https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes\"> Naive Bayes scikit-learn </a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "### Naive Bayes Classifier\n",
    "Naive Bayes Classifier is based on Bayes' theorem where we assume conditional independence among the different pair features given the value of the class label.Given the class label y and features $x_{1}$ through $x_{n}$\n",
    "$$P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) P(x_1, \\dots, x_n \\mid y)}{P(x_1, \\dots, x_n)}$$\n",
    "\n",
    "As we assume them to be conditionally independent hence we can say\n",
    "$$P(x_1, \\dots, x_n \\mid y) = \\prod_{i=1}^{n} P(x_i \\mid y)$$\n",
    "\n",
    "Also as $P(x_1, \\dots, x_n)$ also called evidence, works as a scaling factor to make the probabilites sum up to 1 hence we can remove it to get\n",
    "$$\\begin{align}\\begin{aligned}P(y \\mid x_1, \\dots, x_n) \\propto P(y) \\prod_{i=1}^{n} P(x_i \\mid y)\\\\\\Downarrow\\\\\\hat{y} = \\arg\\max_y P(y) \\prod_{i=1}^{n} P(x_i \\mid y),\\end{aligned}\\end{align}$$\n",
    "\n",
    "Reference: <a href=\"https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes\"> Naive Bayes scikit-learn </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy, f1-score, precision and recall were 0.55, 0.51, 0.68 and 0.55\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"The classification accuracy, f1-score, precision and recall were\",f'{accuracy_score(y_test,y_pred):.2f},',f'{f1_score(y_test,y_pred,average=\"weighted\"):.2f},',f'{precision_score(y_test,y_pred,average=\"weighted\"):.2f}',\"and\",f'{recall_score(y_test,y_pred,average=\"weighted\"):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy, f1-score, precision and recall were 0.82, 0.82, 0.83 and 0.82\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "y_pred = mnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"The classification accuracy, f1-score, precision and recall were\",f'{accuracy_score(y_test,y_pred):.2f},',f'{f1_score(y_test,y_pred,average=\"weighted\"):.2f},',f'{precision_score(y_test,y_pred,average=\"weighted\"):.2f}',\"and\",f'{recall_score(y_test,y_pred,average=\"weighted\"):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy, f1-score, precision and recall were 0.83, 0.83, 0.83 and 0.83\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "y_pred = bnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"The classification accuracy, f1-score, precision and recall were\",f'{accuracy_score(y_test,y_pred):.2f},',f'{f1_score(y_test,y_pred,average=\"weighted\"):.2f},',f'{precision_score(y_test,y_pred,average=\"weighted\"):.2f}',\"and\",f'{recall_score(y_test,y_pred,average=\"weighted\"):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods \n",
    "Meta Learning approach which involves combining multiple base models to get better predictive accuracy.They can be classified into two main categories bootstrap aggregation(bagging) and boosting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrap Aggregation\n",
    "Involves training multiple weak classifiers on bootstrapped data sets,i.e. selecting from training data set with replacement,and voting over the weak classifiers for final prediction.A simple example would be that of Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is a meta ML algorithm which uses the concept of bagging by training multiple decision trees as weak classifiers over bootstrapped data sets from the training data.This kind of bootstrapping allows the decision trees which are trained to be uncorrelated hence reducing the variance of the model.The final prediction is done using a majority vote among the different decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy, f1-score, precision and recall were 0.97, 0.97, 0.97 and 0.97\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "y_pred = rfc.fit(X_train, y_train).predict(X_test)\n",
    "print(\"The classification accuracy, f1-score, precision and recall were\",f'{accuracy_score(y_test,y_pred):.2f},',f'{f1_score(y_test,y_pred,average=\"weighted\"):.2f},',f'{precision_score(y_test,y_pred,average=\"weighted\"):.2f}',\"and\",f'{recall_score(y_test,y_pred,average=\"weighted\"):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting\n",
    "Boosting involves training successive models each new model emphasising more on the misclassified samples of the previous one.Unlike in bagging boosting can be done across different base classifiers.Some examples we will consider here are AdaBoost and Xgboost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost is a boosting algorithm that combines several weak classifiers into a single strong classifier. It operates by iteratively training weak classifiers on data and modifying instance weights based on classification errors. A weighted vote of the weak classifiers is used to make the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy, f1-score, precision and recall were 0.74, 0.74, 0.74 and 0.74\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=100,n_jobs=-1)\n",
    "y_pred = ada.fit(X_train, y_train).predict(X_test)\n",
    "print(\"The classification accuracy, f1-score, precision and recall were\",f'{accuracy_score(y_test,y_pred):.2f},',f'{f1_score(y_test,y_pred,average=\"weighted\"):.2f},',f'{precision_score(y_test,y_pred,average=\"weighted\"):.2f}',\"and\",f'{recall_score(y_test,y_pred,average=\"weighted\"):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XgBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XgBoost or eXtreme Gradient Boost is a software library that implements the Gradient Boosting algorithm with multiple hardware optimizations and regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\pnram\\anaconda3\\envs\\torch_env\\lib\\site-packages (1.6.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\pnram\\anaconda3\\envs\\torch_env\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\pnram\\anaconda3\\envs\\torch_env\\lib\\site-packages (from xgboost) (1.21.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy, f1-score, precision and recall were 0.74, 0.74, 0.74 and 0.74\n"
     ]
    }
   ],
   "source": [
    "xgc = XGBClassifier(n_estimators=100,n_jobs=-1)\n",
    "y_pred = ada.fit(X_train, y_train).predict(X_test)\n",
    "print(\"The classification accuracy, f1-score, precision and recall were\",f'{accuracy_score(y_test,y_pred):.2f},',f'{f1_score(y_test,y_pred,average=\"weighted\"):.2f},',f'{precision_score(y_test,y_pred,average=\"weighted\"):.2f}',\"and\",f'{recall_score(y_test,y_pred,average=\"weighted\"):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Artificial Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Artificial neural networks are combination of non linear logistic units that are capable of outperforming classical machine learning algorithms due to their ability to learn complex feature relationships in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy, f1-score, precision and recall were 0.96, 0.96, 0.96 and 0.96\n"
     ]
    }
   ],
   "source": [
    "# Input 784 - hidden layer 100 -  Output 10\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,)random_state=1, max_iter=300)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "print(\"The classification accuracy, f1-score, precision and recall were\",f'{accuracy_score(y_test,y_pred):.2f},',f'{f1_score(y_test,y_pred,average=\"weighted\"):.2f},',f'{precision_score(y_test,y_pred,average=\"weighted\"):.2f}',\"and\",f'{recall_score(y_test,y_pred,average=\"weighted\"):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
